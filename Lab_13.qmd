---
title: "Lab 13"
subtitle: "MATH 361"
author: "Insert your name here"
date: "Insert due date here"
format: 
  html:
    self-contained: true
    toc: true
    toc_float: true
    number-section: false
    highlight: tango
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this lab, you will use R to construct and explore properties of confidence intervals.

## Load packages

We first need to load the `ggplot2movies` and `tidyverse` packages using the `library()` command. You likely need to install the `ggplot2movies` package since it is your first time using it.  

```{r, message = FALSE, warning = FALSE}
library(ggplot2movies)
library(tidyverse)
library(infer)
```

## Setting a seed

We will take some random samples in this lab. To make sure your results stay consistent each time you knit, we need to *set a seed.* 

### Task 0

Change the value "1234" below to your favorite number. 

```{r}
set.seed(1234)
```

## The data

The `movies` dataset contains a census of all movies on IMDB from the years 1893 to 2005. It includes data on the title, year of release, length in minutes, user ratings, and genre. The following code loads the data.

```{r}
data(movies)
```

You can run `?movies` in your console to read more about the dataset.

## Exploratory Analysis

### Task 1

How many movies are included in the dataset? How many variables?

> YOUR ANSWER HERE

For this lab, we are going to investigate the average user `rating` of all movies in the population. Let's take a quick look at the distribution of movie ratings.

```{r}
ggplot(movies, aes(x = rating)) +
  geom_histogram(color = "white")
```

### Task 2

Describe the distribution. Make sure to comment on skewness and modality.

> YOUR ANSWER HERE

## Parameters and point estimates

Because `movies` is a census, that means we can calculate the true values of $\mu$ and $\sigma$ in the population. 

```{r}
movies %>% 
  summarize(mu = mean(rating),
            sigma = sd(rating))
```

Let's go ahead and save these values as their own objects, to be used in later analyses.

```{r}
mu <- mean(movies$rating)
sigma <- sd(movies$rating)
```

Let's suppose you don't know this census data exists, and you instead need to estimate the average rating from a random sample of data. The following code takes a random sample of size 50.

```{r}
sample50 <- movies %>% 
  sample_n(50)
```

### Task 3

Compute the mean and standard deviation of the ratings in your sample. Remember to name the summary statistics appropriately; that is, you should no longer call them `mu` and `sigma` since you are now computing point estimates rather than population parameters. 

```{r}
#Insert Task 3 code here
```

## Constructing a confidence interval

Recall our formula for computing a confidence interval for $\mu$ when $\sigma$ is known:

$$\bar{x} \ \pm \ z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$$

The following code constructs a 95% confidence interval for $\mu$ using the normal distribution when $\sigma$ is known.

```{r}
z_cutoff <- qnorm(.975)

sample50 %>% 
  summarize(xbar = mean(rating),
            s = sd(rating),
            n = n()) %>% 
  mutate(lower_ci_Z = xbar - z_cutoff*sigma/sqrt(n),
         upper_ci_Z = xbar + z_cutoff*sigma/sqrt(n))
```

### Task 4

Interpret the confidence interval in the context of the problem.

> YOUR ANSWER HERE

Was your confidence interval "successful" in capturing the true parameter? 

> YOUR ANSWER HERE

Remember: in real life, you won't be able to verify whether your particular confidence interval was successful, because you won't have access to the population data. If you did, there would be no reason to construct a confidence interval because you know $\mu$ exactly!

### Task 5

Comment on why the code `z_cutoff <- qnorm(.975)` is used in the code chunk above. That is, what value is stored in `z_cutoff`, and how does it relate to a 95% confidence interval?

> YOUR ANSWER HERE

What code would you use if you instead needed a 99% confidence interval? 

> YOUR ANSWER HERE

What value would be stored in `z_cutoff` in this case?

> YOUR ANSWER HERE

Would you expect this interval to be narrower or wider than the one constructed above?

> YOUR ANSWER HERE

## When $\sigma$ is unknown

Recall that when we only have access to sample data, we also have to rely on $s$ as an estimate of $\sigma$, which adds additional uncertainty to our confidence interval. We use the t-distribution to account for this. The appropriate formula for a confidence interval when $\sigma$ is unknown is given by:

$$\bar{x} \ \pm \ t_{\alpha/2}(n-1)\frac{s}{\sqrt{n}}$$

### Task 6

Copy and paste the code from the previous code chunk, and add two new variables that compute the confidence interval using the t-distribution. Hint: you should first use the `qt()` function to find the appropriate $t_{\alpha/2}(n-1)$ value and save it into an object called `t_cutoff`. 

```{r}
#Insert code here
```

Interpret the confidence interval in the context of this problem.

> YOUR ANSWER HERE

## Properties of confidence intervals

Recall that a statement about "95% confidence" is a statement about our confidence in the *method*. That is, we are confident that constructing the confidence interval around a point estimate in this way will be successful at capturing the true parameter 95% of the time. 

Let's take advantage of the fact that we have the population data and explore what we mean by 95% confidence by taking *many* random samples. Recall that the function `rep_sample_n()` from the `infer` package allows us to do this. Here we start by taking 5 samples, each of size 50. 

```{r}
five_samples <- rep_sample_n(movies, size = 50, 
                            reps = 5, replace = TRUE)
```

The following code `summarize`s each sample (`group_by(replicate)`) by computing the sample mean and sample standard deviation.

```{r}
five_samples %>% 
  group_by(replicate) %>% 
  summarise(xbar = mean(rating),
            s = sd(rating),
            n = n())
```

We can add onto that "chain" of code and construct the confidence interval for each sample as well. Let's save our results as `five_samples_CIs`.

```{r, echo = FALSE}
t_cutoff <- qt(.975, df = 49)
```


```{r}
five_samples_CIs <- five_samples %>% 
  group_by(replicate) %>% 
  summarise(xbar = mean(rating),
            s = sd(rating),
            n = n()) %>% 
  mutate(lower_ci_Z = xbar - z_cutoff*sigma/sqrt(n),
         upper_ci_Z = xbar + z_cutoff*sigma/sqrt(n),
         lower_ci_t = xbar - t_cutoff*s/sqrt(n),
         upper_ci_t = xbar + t_cutoff*s/sqrt(n))
five_samples_CIs
```

What proportion of these intervals contain the true $\mu$? We could determine this manually by simply looking at the output, but this will quickly become cumbersome with more samples, so let's have R do the heavy lifting for us. 

```{r}
five_samples_CIs %>% 
  summarise(prop_z = sum(lower_ci_Z <= mu & upper_ci_Z >= mu)/n(),
            prop_t = sum(lower_ci_t <= mu & upper_ci_t >= mu)/n())
```

Of course, five samples is not enough simulations to truly investigate the properties of confidence intervals in the long run. Let's take many, many more samples.

### Task 7

Copy, paste, tweak relevant code above to draw 100,000 random samples of size 50 from the `movies` dataset. Call this new dataset `many_samples`.

```{r}
#Insert code here
```

Verify that you have an object in your Environment called `many_samples` with 500,000 rows and 25 variables before continuing. 

### Task 8

Copy, paste, tweak relevant code to compute the sample mean and sample standard deviation as well as the confidence intervals in each sample. Save these results in `many_samples_CIs`.

```{r}
#Insert code here
```

Verify that `many_samples_CIs` has 100,000 rows before proceeding.

### Task 9

Based on the way we defined `z_cutoff` and `t_cutoff` earlier in the lab, what proportion of the 100,000 confidence intervals do you expect to successfully capture the true $\mu$?

> YOUR ANSWER HERE

Copy, paste, tweak relevant code to compute the proportion of the 100,000 intervals that contain $\mu$.

```{r}
#Insert code here
```

Does this match your expectations?

> YOUR ANSWER HERE

### Task 10

If we had instead defined `z_cutoff <- qnorm(.95)` and `t_cutoff <- qt(.95, 50 - 1)`, what proportion of the 100,000 confidence intervals do you expect would have captured the true mean? 

> YOUR ANSWER HERE

### Bonus

Suppose we only know $s$ (not $\sigma$) but we decide to use the normal distribution to construct our confidence interval anyway. That is, we use $$\bar{x} \ \pm \ z_{\alpha/2}\frac{s}{\sqrt{n}}$$

Add two additional variables to your `many_samples_CIs` data frame that compute the lower and upper bounds using this new (incorrect) formula for the confidence interval.

```{r}
#Insert code here
```

Compute the proportion of these intervals that contain $\mu$.

```{r}
#Insert code here
```

If we claim we are 95% confident about an interval constructed using this formula, are we understating or overstating our confidence? Which is worse in terms of integrity/transparency in reporting uncertainty?

> YOUR ANSWER HERE

## Additional (Optional) Exploration

### Sampling distributions and confidence intervals

We can use the sample means of our many random sample to visualize the sampling distribution of $\bar{x}$. Remove `eval = FALSE` from the code chunks as you proceed.

```{r, eval = FALSE}
ggplot(many_samples_CIs, aes(x = xbar)) +
  geom_histogram(color = "white") +
  geom_vline(xintercept = mu, color = "blue")
```

The plot includes a blue vertical line to mark the true $\mu$ value. As the Central Limit Theorem suggests, the sampling distribution of $\bar{x}$ is centered around $\mu$. That is, $E(\bar{x}) = \mu = 5.93$. We also expect from the CLT that $SD(\bar{x}) = \frac{\sigma}{\sqrt{n}} = \frac{1.55}{\sqrt{50}} = 0.219$. We can verify this by computing the mean and standard deviation of the 100,000 `xbar` values from our simulations.

```{r, eval = FALSE}
many_samples_CIs %>% 
  summarize(EXbar = mean(xbar),
            SDXbar = sd(xbar))
```

Let's return to our original sample of size 50. We can visualize the confidence interval on top of the sampling distribution using the following code.

```{r, eval = FALSE}
sample50_CI <- sample50 %>% 
  summarize(xbar = mean(rating),
            s = sd(rating),
            n = n()) %>% 
  mutate(lower_ci_Z = xbar - z_cutoff*sigma/sqrt(n),
         upper_ci_Z = xbar + z_cutoff*sigma/sqrt(n))

ggplot(many_samples_CIs, aes(x = xbar)) +
  geom_histogram(color = "white") +
  geom_vline(xintercept = mu, color = "blue") +
  geom_vline(xintercept = sample50_CI$xbar, color = "red") +
  shade_ci(c(sample50_CI$lower_ci_Z, sample50_CI$upper_ci_Z))
```

This helps us to see that the vast majority (e.g. 95%) of the point estimates in the distribution falls close enough to $\mu$ that the shaded region will include the blue vertical line. That is, the vast majority of random samples will result in a point estimate $\bar{x}$ and corresponding confidence interval that will contain $\mu$. 

It is possible that we get an "unfortunate" random sample that gives us a point estimate that is far from the parameter, and the corresponding confidence interval will *not* capture $\mu$. The following plot shows one such example.

```{r, echo = FALSE, eval = FALSE}
unfortunate_CI <- many_samples_CIs %>% 
  #sort data set by upper confidence limits from least to greatest
  arrange(upper_ci_Z) %>% 
  # this will result in the first ~2500 rows (2.5% of 100,000) having 
  # upper_ci_Z values smaller than mu
  # these 2500 rows will result in "unfortunate" confidence intervals
  # use slice() to choose any row <2500. 437 happens to be my favorite number :)
  slice(437)

ggplot(many_samples_CIs, aes(x = xbar)) +
  geom_histogram(color = "white") +
  geom_vline(xintercept = mu, color = "blue") +
  geom_vline(xintercept = unfortunate_CI$xbar, color = "red") +
  shade_ci(c(unfortunate_CI$lower_ci_Z, unfortunate_CI$upper_ci_Z))
```

For 95% confidence intervals, this will happen about 5% of the time. That is, 5% of random samples give us point estimates that fall far enough out in the tails that a 95% confidence interval will not "reach far enough" to include $\mu$. If we construct wider intervals around the point estimates (say 99% confidence intervals), we increase our probability of capturing $\mu$ (to 99%), but at the expense of a less informative (wider) interval.  
